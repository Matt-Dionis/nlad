- TypeScript
- Next.js
- Node.js
- ESLint
- Prettier
- shadcn components
- TailwindCSS
- SQL
- postgres
- Drizzle ORM
- Neon DB
- Vercel
- Cloudflare
- Anthropic Claude Sonnet 3.5 (latest) for an LLM model
- Anthropic prompt-caching (`cache_control`) for static system messages and static message summaries (could be part of the memory implementation)
- Key-Value (KV) stores where appropriate
- Asynchronous triggers where appropriate (potentially leverage memory to proactively start interaction with users)
- Custom Model Context Protocol (MCP), if necessary
- Optimized system messages
- GrubHub and/or Doordash API integration, if it enables great features
- Innovative use of structured LLM outputs to enable deterministic features within an otherwise mainly probabilistic (LLM-backed) application
